{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.decomposition import KernelPCA as kpca\n",
    "from sklearn.metrics import roc_curve, auc,roc_auc_score,f1_score,confusion_matrix\n",
    "import numpy as np\n",
    "print (__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename=\"apnea.csv\"\n",
    "f = open(filename)\n",
    "f.readline()  # skip the header\n",
    "data =  np.loadtxt(fname = f, delimiter = ',',dtype='double')\n",
    "Y = data[:,data.shape[1]-1]\n",
    "X = data[:,1:data.shape[1]-1] \n",
    "\n",
    "# Reading the labels now\n",
    "f= open(filename)\n",
    "labels_=np.loadtxt(fname=f,delimiter=',',dtype='string')\n",
    "labels_=labels_[0,1:data.shape[1]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  [[  1.   1.   3. ...,   0.  31.   1.]\n",
      " [  1.   1.   3. ...,   4.  31.   1.]\n",
      " [  1.   1.   3. ...,   3.  30.   2.]\n",
      " ..., \n",
      " [  1.   3.   4. ...,   1.  29.   1.]\n",
      " [  2.   4.   4. ...,   0.  34.   1.]\n",
      " [  1.   4.   4. ...,   0.  33.   2.]]\n",
      "Y:  [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  0.  1.  0.  1.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.\n",
      "  0.  1.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  0.\n",
      "  0.  1.  1.  1.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.  0.  1.\n",
      "  0.  1.  1.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.  1.\n",
      "  1.  0.  1.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  0.  1.  0.  1.\n",
      "  1.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.\n",
      "  1.  1.  0.  1.  0.  1.  1.  1.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.\n",
      "  1.  1.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.\n",
      "  1.  0.  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#** Reading File into Numpy Array **\n",
    "print 'X: ',X\n",
    "print 'Y: ',Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Normalizing to Zero Mean Unit Variance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = X.mean(axis=0)\n",
    "std = X.std(axis=0)\n",
    "X = (X - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16  Labels selected are:  ['AGASGA' 'STEROIDS' 'DEXABETA' 'DELVMODE' 'APG1MIN' 'APG5MIN' 'RESUSNEED'\n",
      " 'MODERESUS' 'BWT' 'HC_Birth' 'HRday1' 'HR48HRS' 'HR72HRS'\n",
      " 'Desaturation1_3DAYS' 'Gestation' 'Sex']\n"
     ]
    }
   ],
   "source": [
    "print labels_.shape[0],' Labels selected are: ',labels_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**POST Normalization, we Have:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization gives:  [[-0.51483827 -1.99629336  0.15054546 ..., -0.33839133  0.67872844\n",
      "  -0.96248655]\n",
      " [-0.51483827 -1.99629336  0.15054546 ...,  0.7294969   0.67872844\n",
      "  -0.96248655]\n",
      " [-0.51483827 -1.99629336  0.15054546 ...,  0.46252484  0.18766685\n",
      "   1.03897555]\n",
      " ..., \n",
      " [-0.51483827 -0.04353288  1.20101823 ..., -0.07141928 -0.30339474\n",
      "  -0.96248655]\n",
      " [ 1.69967155  0.93284737  1.20101823 ..., -0.33839133  2.1519132\n",
      "  -0.96248655]\n",
      " [-0.51483827  0.93284737  1.20101823 ..., -0.33839133  1.66085161\n",
      "   1.03897555]]\n"
     ]
    }
   ],
   "source": [
    "# Post Normalization\n",
    "print 'Normalization gives: ',X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A=data\n",
    "unqA = np.unique(A[:,A.shape[1]-1])\n",
    "out = {unqA[i]:A[A[:,A.shape[1]-1]==unqA[i],0:A.shape[1]-1] for i in range(len(unqA))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_0=out[0][:,1:out[0].shape[1]]\n",
    "X_1=out[1][:,1:out[1].shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   2.   2. ...,   0.  30.   1.]\n",
      " [  1.   2.   2. ...,   0.  28.   1.]\n",
      " [  1.   4.   3. ...,   0.  32.   1.]\n",
      " ..., \n",
      " [  1.   3.   4. ...,   1.  29.   1.]\n",
      " [  2.   4.   4. ...,   0.  34.   1.]\n",
      " [  1.   4.   4. ...,   0.  33.   2.]] \n",
      "\n",
      "[[  1.   1.   3. ...,   0.  31.   1.]\n",
      " [  1.   1.   3. ...,   4.  31.   1.]\n",
      " [  1.   1.   3. ...,   3.  30.   2.]\n",
      " ..., \n",
      " [  1.   4.   4. ...,   0.  32.   2.]\n",
      " [  1.   2.   2. ...,   0.  32.   1.]\n",
      " [  1.   1.   3. ...,   0.  33.   2.]] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print X_0,'\\n\\n',X_1,'\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_0:  [[-0.51483827 -1.01991312 -0.89992731 ..., -0.33839133  0.18766685\n",
      "  -0.96248655]\n",
      " [-0.51483827 -1.01991312 -0.89992731 ..., -0.33839133 -0.79445632\n",
      "  -0.96248655]\n",
      " [-0.51483827  0.93284737  0.15054546 ..., -0.33839133  1.16979002\n",
      "  -0.96248655]\n",
      " ..., \n",
      " [-0.51483827 -0.04353288  1.20101823 ..., -0.07141928 -0.30339474\n",
      "  -0.96248655]\n",
      " [ 1.69967155  0.93284737  1.20101823 ..., -0.33839133  2.1519132\n",
      "  -0.96248655]\n",
      " [-0.51483827  0.93284737  1.20101823 ..., -0.33839133  1.66085161\n",
      "   1.03897555]] \n",
      "X_1:  [[-0.51483827 -1.99629336  0.15054546 ..., -0.33839133  0.67872844\n",
      "  -0.96248655]\n",
      " [-0.51483827 -1.99629336  0.15054546 ...,  0.7294969   0.67872844\n",
      "  -0.96248655]\n",
      " [-0.51483827 -1.99629336  0.15054546 ...,  0.46252484  0.18766685\n",
      "   1.03897555]\n",
      " ..., \n",
      " [-0.51483827  0.93284737  1.20101823 ..., -0.33839133  1.16979002\n",
      "   1.03897555]\n",
      " [-0.51483827 -1.01991312 -0.89992731 ..., -0.33839133  1.16979002\n",
      "  -0.96248655]\n",
      " [-0.51483827 -1.99629336  0.15054546 ..., -0.33839133  1.66085161\n",
      "   1.03897555]]\n"
     ]
    }
   ],
   "source": [
    "X_0 = (X_0 - mean) / std\n",
    "X_1 = (X_1 - mean) / std\n",
    "\n",
    "print 'X_0: ',X_0,'\\nX_1: ',X_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance contributed by each PC by order is:  [ 0.2113572   0.14540507  0.11550571]\n",
      "MLE Method Parameters Chosen:  3\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pylab as pylab\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# To getter a better understanding of interaction of the dimensions\n",
    "# plot the first three PCA dimensions\n",
    "fig = plt.figure(1, figsize=(18, 10))\n",
    "ax = Axes3D(fig, elev=-150, azim=110)\n",
    "# Replace mle with any number of components desired for analysis\n",
    "\n",
    "PCA_var = PCA(n_components=3)\n",
    "X_0_red =PCA_var.fit_transform(X_0)\n",
    "X_1_red =PCA_var.fit_transform(X_1)\n",
    "print 'The variance contributed by each PC by order is: ',PCA_var.explained_variance_ratio_\n",
    "print 'MLE Method Parameters Chosen: ',PCA_var.n_components_\n",
    "\n",
    "ax.scatter(X_0_red[:, 0], X_0_red[:, 1], X_0_red[:, 2], c=np.ones(X_0_red.shape[0]),label='No Apnea',cmap=plt.cm.Greys_r)\n",
    "ax.scatter(X_1_red[:, 0], X_1_red[:, 1], X_1_red[:, 2], c=np.zeros(X_1_red.shape[0]), marker='x',label='Apnea',cmap=plt.cm.Greys_r)\n",
    "# for Default colormap: Class 0: Blue Class 1: Red\n",
    "\n",
    "ax.set_xlabel(\"1st eigenvector\")\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.set_ylabel(\"2nd eigenvector\")\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.set_zlabel(\"3rd eigenvector\")\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "ax.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using varying kernels allows for Non-linear manifold representations\n",
    "\n",
    "## Kernel PCA\n",
    "\n",
    "**It's clear from the representation below, that the dataset forms three distinct clusters, that can be segregated using a high-dimensional non-linear classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(18, 10))\n",
    "ax = Axes3D(fig, elev=-150, azim=110)\n",
    "PCA_var= kpca(n_components=3,kernel='sigmoid')\n",
    "PCA_var.fit(X)\n",
    "# X_reduced=PCA_var.fit_transform(X)\n",
    "X_0_red =PCA_var.transform(X_0)\n",
    "X_1_red =PCA_var.transform(X_1)\n",
    "\n",
    "ax.scatter(X_0_red[:, 0], X_0_red[:, 1], X_0_red[:, 2], c=np.zeros(X_0_red.shape[0]),label='No Apnea',cmap=plt.cm.Greys_r)\n",
    "ax.scatter(X_1_red[:, 0], X_1_red[:, 1], X_1_red[:, 2], c=np.ones(X_1_red.shape[0]), marker='x',label='Apnea',cmap=plt.cm.Greys_r)\n",
    "# ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=Y,cmap=plt.cm.spectral)\n",
    "ax.set_xlabel(\"1st eigenvector\")\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.set_ylabel(\"2nd eigenvector\")\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.set_zlabel(\"3rd eigenvector\")\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "ax.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Confusion Matrix Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_labels_=np.array(['Group 1','Group 2','Group 3'])\n",
    "def plot_confusion_matrix(cm,name,title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_labels_))\n",
    "    plt.xticks(tick_marks,class_labels_, rotation=45)\n",
    "    plt.yticks(tick_marks,class_labels_)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINING MODELS BELOW: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "f = open(filename)\n",
    "f.readline()  # skip the header\n",
    "data =  np.loadtxt(fname = f, delimiter = ',',dtype='double')\n",
    "Y = data[:,0]\n",
    "X = data[:, 1:data.shape[1]]  # we only take the first two features.\n",
    "names = [\"Nearest Neighbors\", \"RBF SVM\", \"Decision Tree\",\n",
    "         \"Random Forest\", \"Naive Bayes\"]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    SVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "\n",
    "#Normalizing to Zero Mean Unit variance\n",
    "\n",
    "mean = X.mean(axis=0)\n",
    "std = X.std(axis=0)\n",
    "X = (X - mean) / std\n",
    "\n",
    "\n",
    "# preprocess dataset, split into training and test part\n",
    "# standardize\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.3)\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    y_predic=clf.predict(X_test)\n",
    "    print 'Classifier: ',name,' Accuracy: ',score\n",
    "    cm=confusion_matrix(y_test,y_predic)\n",
    "    np.set_printoptions(precision=2)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cm_normalized,name,title='Normalized confusion matrix for '+name)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
